### 2017-08
- Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders, Zhao et al 2017, ['arXiv'](https://arxiv.org/abs/1703.10960)
- How to Train Your DRAGAN, Kodali et al 2017. [arXiv](https://arxiv.org/abs/1705.07215)
- Improved Training of Wasserstein GANs, Gulrajani et al 2017. [arXiv](https://arxiv.org/abs/1704.00028)
- Wasserstein Gan, Arjovsky et al 2017. [arXiv](https://arxiv.org/abs/1701.07875), [blog/code](https://wiseodd.github.io/techblog/2017/02/04/wasserstein-gan/)
- Reading Scene Text in Deep Convolutional Sequences, He et al, 2016. [arXiv](https://arxiv.org/abs/1506.04395)
### 2017-03
- Scheduled Sampling for Sequence Prediction with RNN, [summary](summaries/scheduled_sampling.md), [arXiv](https://arxiv.org/abs/1506.03099), Bengio et al, 2015
- Hybrid computing using a neural network with dynamic external memory, published in [Nature](https://www.dropbox.com/s/0a40xi702grx3dq/2016-graves.pdf)
- Neural Turing Machine, [arXiv](https://arxiv.org/abs/1410.5401)
- Memory Networks, [arXiv](https://arxiv.org/abs/1410.3916)
- Deep Photo Style Transfer, [arXiv](https://arxiv.org/abs/1703.07511)
- Matching Networks for One Shot Learning, Vinyals et al, NIPS 2016. [my summary](summaries/matching_networks.md), [arXiv](https://arxiv.org/abs/1606.04080). Unofficial [code in TF](https://github.com/zergylord/oneshot). [karpathy notes](http://www.shortscience.org/paper?bibtexKey=journals/corr/VinyalsBLKW16#karpathy), [Colyer blog](https://blog.acolyer.org/2017/01/03/matching-networks-for-one-shot-learning/)

### 2017-01
- Optimization As A Model For Few-Shot Learning, Sachin Ravi and Hugo Larochelle, ICLR 2017. [openreview](https://openreview.net/pdf?id=rJY0-Kcll), [video](https://www.youtube.com/watch?v=igJmB6d8y8E)
- NIPS 2016 Tutorial:Generative Adversarial Networks, [annotated](https://drive.google.com/file/d/0ByV7wn2NzevOa2RqZmJVR2hrUTA/view?usp=sharing),[arXiv](https://arxiv.org/abs/1701.00160), [blog/code](https://wiseodd.github.io/techblog/2016/09/17/gan-tensorflow/)

### 2016-11
- [Fully Character-Level Neural Machine Translation without Explicit Segmentation](summaries/fully_char_level_nmt.md), [annotated](https://drive.google.com/open?id=0ByV7wn2NzevOQ0JtTTRuR0pjUlE), [arXiv](https://arxiv.org/abs/1610.03017)
- [Neural Machine Translation by Jointly Learning to Align and Translate](summaries/neural_machine_translation.md), [annotated](https://drive.google.com/file/d/0ByV7wn2NzevOS3FmWHVNazhnczA/view?usp=sharing), [arXiv](https://arxiv.org/abs/1409.0473)
- [Sequence to Sequence Learning with Neural Networks](summaries/seq2seq_nn.md), [annotated](https://drive.google.com/file/d/0ByV7wn2NzevOQ1l5aUF4RWYtenc/view?usp=sharing), [arXiv](https://arxiv.org/abs/1409.3215)
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](summaries/learning_phrase_rep_RNN_encoder_decoder_mt.md), [arXiv](https://arxiv.org/abs/1406.1078)
- [Implicit Discourse Relation Detection via a Deep Architecture with Gated Relevance Network](summaries/implicit_drd_grn.md), [annotated](https://drive.google.com/file/d/0ByV7wn2NzevOLUxtemFqejJmNVU/view?usp=sharing), [acl](https://www.aclweb.org/anthology/P/P16/P16-1163.pdf)

### 2016-10
- [Auto-Encoding Variational Bayes](summaries/auto-encoding_var_bayes.md), [annotated](https://drive.google.com/file/d/0ByV7wn2NzevOcjBIeVBZcTFUQ2s/view?usp=sharing), [arXiv](https://arxiv.org/abs/1312.6114), [blog/code](https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/), conditional VAE [blog/code](https://wiseodd.github.io/techblog/2016/12/17/conditional-vae/), [code](https://github.com/hwalsuklee/tensorflow-mnist-CVAE)
- [Semi-supervised Variational Autoencoders for Sequence Classification](summaries/var_auto_sequence_class.md), [annotated](https://drive.google.com/file/d/0ByV7wn2NzevOTXEzLWlNQy1od0k/view?usp=sharing), [arXiv](https://arxiv.org/abs/1603.02514)
- [Autoencoder review](summaries/autoencoders.md) by Keras author Francois Chollet

# Deep Learning Resources
Resources for deep learning: papers, articles, courses  

## Datasets
- UCI [machine learning repository](https://archive.ics.uci.edu/ml/datasets.html?format=&task=&att=&area=&numAtt=&numIns=&type=&sort=instDown&view=table). 360 datasets, some very large. Nice sorting feature, such as ">1000 instance/classification/text" results in [14 data sets](https://archive.ics.uci.edu/ml/datasets.html?format=&task=cla&att=&area=&numAtt=&numIns=greater1000&type=&sort=instDown&view=table)

## Paper collections
- ["Awesome deep learning papers"]https://github.com/terryum/awesome-deep-learning-papers/), a collection of 100 best papers from past few years
- Paper collection by [songrotek](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md)

## Overview
- [Nature Review article. Lecun, Bengio, Hinton. 2015](http://www.nature.com/articles/nature14539.epdf?referrer_access_token=K4awZz78b5Yn2_AoPV_4Y9RgN0jAjWel9jnR3ZoTv0PU8PImtLRceRBJ32CtadUBVOwHuxbf2QgphMCsA6eTOw64kccq9ihWSKdxZpGPn2fn3B_8bxaYh0svGFqgRLgaiyW6CBFAb3Fpm6GbL8a_TtQQDWKuhD1XKh_wxLReRpGbR_NdccoaiKP5xvzbV-x7b_7Y64ZSpqG6kmfwS6Q1rw%3D%3D&tracking_referrer=www.nature.com)
  * Good short overview
- [Schmidhuber, J. (2015). Deep learning in neural networks: An overview. Neural Networks, 61, 85â€“117.](http://arxiv.org/abs/1404.7828)
    * Extensive overview

## Neural Networks

- [Michael Nielsen book on NN](http://neuralnetworksanddeeplearning.com/chap1.html)
- [Hacker's guide to Neural Networks. Andrej Karpathy blog](http://karpathy.github.io/neuralnets/)
- [Visualize NN training](http://experiments.mostafa.io/public/ffbpann/)

## Backpropagation

- [A Gentle Introduction to Backpropagation. Sathyanarayana (2014)](http://numericinsight.com/uploads/A_Gentle_Introduction_to_Backpropagation.pdf)
- [Learning representations by back-propagating errors. Hinton et al, 1986](http://www.nature.com/nature/journal/v323/n6088/abs/323533a0.html)
  * Seminal paper by Hinton et al on back-propagation.
- [The Backpropagation Algorithm](http://page.mi.fu-berlin.de/rojas/neural/chapter/K7.pdf)
  * Longer tutorial on the topic, 34 pages
- [Overview of various optimization algorithms](http://sebastianruder.com/optimizing-gradient-descent/)
  * [Summary](summaries/overview_optimization.md)

## Recurrent Neural Network (RNN)

- [Blog intro, tutorial](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)
- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. Cho et al. 2014)](http://arxiv.org/abs/1406.1078)
- [Character-Aware Neural Language Models. Kim et al. 2015.](http://arxiv.org/pdf/1508.06615.pdf)
- [The Unreasonable Effectiveness of Recurrent Neural Networks. Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
  * Indepth, examples in vision and NLP. Provides code
- [Sequence-to-Sequence Learning with Neural Networks. Sutskever et al (2014)](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)
  * Ground-breaking work on machine translation with RNN and LSTM
- [Training RNN. Sutskever thesis. 2013](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)
  * Indepth, self-contained, 85 pages
- [Understanding Natural Language with Deep Neural Networks Using Torch (2015)](http://devblogs.nvidia.com/parallelforall/understanding-natural-language-deep-neural-networks-using-torch/)
  * See part on predicting next word with RNN.
- [LSTM BASED RNN ARCHITECTURES FOR LARGE VOCABULARY SPEECH RECOGNITION](http://arxiv.org/pdf/1402.1128v1.pdf)
- [Awesome Recurrent Neural Networks](https://github.com/kjw0612/awesome-rnn#lectures)
  * Curated list of RNN resources

## Convolutional Neural Network (CNN, or ConvNet)
- [Character-level Convolutional Networks for Text Classification](http://arxiv.org/abs/1509.01626)
  * [Annotated](https://drive.google.com/open?id=0ByV7wn2NzevOZEw4QV9tbFNyVTQ)
- [Collobert. Natural Language Processing (Almost) from Scratch (2011)](http://dl.acm.org/citation.cfm?id=2078186)
  * Spurred interest in applying CNN to NLP.
- [Multichannel Variable-Size Convolution for Sentence Classification. Yin, 2015](https://aclweb.org/anthology/K/K15/K15-1021.pdf)
  * Interesting, borrows multichannel from image CNN, where each channel is a different word embedding.
- [A CNN for Modelling Sentences. Kalchbrenner et al, 2014](http://phd.nal.co/papers/Kalchbrenner_DCNN_ACL14)
  * Dynamic k-max pooling for variable length sentences. 
- [Semantic Relation Classification via Convolutional Neural Networks with Simple Negative Sampling. Xu et al, 2015](http://arxiv.org/pdf/1506.07650v1.pdf)
- [Text Understanding from Scratch. Zhang, LeCunn. (2015)](http://arxiv.org/abs/1502.01710)
- [Kim. Convolutional Neural Networks for Sentence Classification (2014)](http://arxiv.org/pdf/1408.5882v2.pdf)
- [Sensitivity Analysis of (And Practitioner's Guide to) CNN for Sentence Classification. Zhang, Wallace (2015)](http://arxiv.org/pdf/1510.03820v2.pdf)
  * [Annotated](https://drive.google.com/open?id=0ByV7wn2NzevOY25JNlJQREVLZEU)
- [Relation Extraction: Perspective from Convolutional Neural Networks. Nguyen, Grishman (2015)](http://www.cs.nyu.edu/~thien/pubs/vector15.pdf)
  * [Annotated](https://drive.google.com/file/d/0ByV7wn2NzevObzAtV1QyUDl5X2M/view?usp=sharing)
- [Convolutional Neural Network for Sentence Classification. Yahui Chen, 2015](https://uwspace.uwaterloo.ca/bitstream/handle/10012/9592/Chen_Yahui.pdf?sequence=3&isAllowed=y)
  * Master's thesis, University of Waterloo

## Deep Reinforcement Learning
- [Playing Atari with Deep Reinforcement Learning. Mnih et al. (2014)](http://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)
- [Youtube Demo](https://www.youtube.com/watch?v=wfL4L_l4U9A)

## Other applications of DL
- [Evolving Neural Networks through Augmenting Topologies. Stanley, Miikkulainen (2002)](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf)
- [Implementation of Evolutionary Algorithms for Deep Architectures. Sreenivas Sremath Tirumala (2014)](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.664.6933)
- [DL in Finance](http://arxiv.org/pdf/1602.06561v2.pdf)

## General Topics

- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. Ioffe & Szegedy, 2015](http://arxiv.org/abs/1502.03167)
  * [Annotated](https://drive.google.com/open?id=0ByV7wn2NzevOSW9jVC14VEpSUHc)
- [Dropout: A Simple Way to Prevent NNs from Overfitting. Srivastava, Hinton et al. 2014](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)
- [Problem of vanishing gradients](http://neuralnetworksanddeeplearning.com/chap5.html#the_vanishing_gradient_problem)
  * [Summary](summaries/vanishing_gradients.md)
- [Simple end-to-end in TensorFlow](http://bcomposes.com/2015/11/26/simple-end-to-end-tensorflow-examples/)
  * [Summary](summaries/end-to-end_tf.md)

## Online Courses

- [Deep Learning. Udacity, 2015](https://www.udacity.com/course/deep-learning--ud730)
  * Very brief. It is more about getting a feel for DL and specifically about using TensorFlow for DL.
- [Convolutional Neural Networks for Visual Recognition. Stanford, 2016](http://cs231n.stanford.edu/)
- [Neural Network Course. UniversitÃ© de Sherbrooke, 2013](http://info.usherbrooke.ca/hlarochelle/neural_networks/description.html)
- [Machine Learning Course, University of Oxford(2014-2015)](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/)
- [Deep Learning for NLP, Stanford (2015)](http://cs224d.stanford.edu/)
  * Click "syllabus" for full material
- [Stanford Deep Learning tutorials](http://ufldl.stanford.edu/tutorial/)
  * From basics of Machine Learning, to DNN, CNN, and others. 
  * Includes code. 
- Bengio 3 part lecture series on DL
  * Part [1](https://www.youtube.com/watch?v=JuimBuvEWBg)
  * [2](https://www.youtube.com/watch?v=Fl-W7_z3w3o)
  * [3](https://www.youtube.com/watch?v=_cohR7LAgWA)

## Books

- [Yoshua Bengio, Ian Goodfellow and Aaron Courville (2015). Deep Learning. Book in preparation for MIT Press.](http://www.deeplearningbook.org)

## Lecture Notes
- [Natural Language Understanding with Distributed Representation](http://arxiv.org/pdf/1511.07916v1.pdf)
- Video Lectures: http://techtalks.tv/natural-language-processing-nyu/
- [A Primer on Neural Network Models for Natural Language Processing] (http://u.cs.biu.ac.il/~yogo/nnlp.pdf)

## Other Reading Lists
[DeepLearning.net's list]
(http://deeplearning.net/reading-list/)

## Tools
- [TensorFlow](https://www.tensorflow.org)
  * [white paper](http://download.tensorflow.org/paper/whitepaper2015.pdf)
- [Torch](http://torch.ch)
  * [Learn Lua in 15 minutes](http://tylerneylon.com/a/learn-lua/)
- [Deeplearning4j](http://deeplearning4j.org)
- [Theano](http://deeplearning.net/software/theano/)
